{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Seguridad Multimodal Inteligente\n",
    "\n",
    "Este notebook implementa un sistema de seguridad avanzado capaz de detectar personas y reconocer rostros en videos utilizando t√©cnicas de **Visi√≥n por Computador Ultra-Ligeras**.\n",
    "\n",
    "### üöÄ Caracter√≠sticas Principales\n",
    "- **Detecci√≥n Ultra-Ligera**: Usa Haar Cascades para funcionar en dispositivos de bajos recursos (Raspberry Pi).\n",
    "- **Reconocimiento Geom√©trico**: Identifica personas bas√°ndose en ratios faciales √∫nicos (distancia ojos, nariz, boca) sin necesidad de redes neuronales pesadas.\n",
    "- **Tracking Inteligente**: Sistema de estados para evitar alertas repetitivas mientras una persona permanece en c√°mara.\n",
    "\n",
    "### üõ†Ô∏è Tecnolog√≠as\n",
    "- **OpenCV**: Procesamiento de imagen y detecci√≥n.\n",
    "- **Python**: L√≥gica del sistema.\n",
    "- **Matplotlib**: Visualizaci√≥n de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n e Instalaci√≥n\n",
    "Instalamos las librer√≠as necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.12/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict\n",
    "import time\n",
    "\n",
    "# Configuraci√≥n para mostrar im√°genes en el notebook\n",
    "def show_frame(frame, title=\"Frame\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. M√≥dulo de Detecci√≥n (LightweightDetector)\n",
    "Este m√≥dulo utiliza **Haar Cascades** de OpenCV para detectar rostros y ojos. Es extremadamente r√°pido y eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Detection:\n",
    "    \"\"\"Estructura de datos para una detecci√≥n.\"\"\"\n",
    "    x: int\n",
    "    y: int\n",
    "    width: int\n",
    "    height: int\n",
    "    confidence: float = 1.0\n",
    "    landmarks: Optional[dict] = None\n",
    "\n",
    "class LightweightDetector:\n",
    "    \"\"\"\n",
    "    Detector ultra-ligero usando Haar Cascades.\n",
    "    Optimizado para rendimiento en CPU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Cargar clasificadores pre-entrenados\n",
    "        # Nota: En Colab/Local puede requerir rutas absolutas si no encuentra los archivos xml\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "        \n",
    "    def detect(self, frame: np.ndarray) -> List[Detection]:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detectar caras\n",
    "        faces = self.face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        detections = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Buscar ojos dentro de la regi√≥n de la cara\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            eyes = self.eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "            \n",
    "            landmarks = None\n",
    "            # Si encontramos 2 ojos, podemos estimar la geometr√≠a\n",
    "            if len(eyes) >= 2:\n",
    "                # Ordenar ojos por posici√≥n X\n",
    "                eyes = sorted(eyes, key=lambda e: e[0])\n",
    "                left_eye = (x + eyes[0][0] + eyes[0][2]//2, y + eyes[0][1] + eyes[0][3]//2)\n",
    "                right_eye = (x + eyes[1][0] + eyes[1][2]//2, y + eyes[1][1] + eyes[1][3]//2)\n",
    "                \n",
    "                # Estimar boca y nariz basado en proporciones antropom√©tricas est√°ndar\n",
    "                mouth_center = (x + w//2, y + int(h * 0.75))\n",
    "                nose_center = (x + w//2, y + int(h * 0.55))\n",
    "                chin_center = (x + w//2, y + h)\n",
    "                \n",
    "                landmarks = {\n",
    "                    \"left_eye\": left_eye,\n",
    "                    \"right_eye\": right_eye,\n",
    "                    \"mouth\": mouth_center,\n",
    "                    \"nose\": nose_center,\n",
    "                    \"chin\": chin_center\n",
    "                }\n",
    "            \n",
    "            detections.append(Detection(x, y, w, h, 1.0, landmarks))\n",
    "            \n",
    "        return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. M√≥dulo de Reconocimiento (GeometricRecognizer)\n",
    "Este m√≥dulo extrae \"firmas geom√©tricas\" de los rostros. A diferencia de los embeddings de Deep Learning, esto usa matem√°ticas simples sobre las distancias entre puntos clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometricRecognizer:\n",
    "    \"\"\"\n",
    "    Reconocimiento facial basado en ratios geom√©tricos.\n",
    "    \"\"\"\n",
    "    def __init__(self, tolerance: float = 0.15):\n",
    "        self.tolerance = tolerance\n",
    "        self.known_profiles = {}  # {id: {\"name\": str, \"ratios\": list}}\n",
    "    \n",
    "    def extract_ratios(self, landmarks: dict) -> Optional[List[float]]:\n",
    "        \"\"\"Extrae 4 ratios geom√©tricos √∫nicos del rostro.\"\"\"\n",
    "        if not landmarks:\n",
    "            return None\n",
    "            \n",
    "        le = np.array(landmarks[\"left_eye\"])\n",
    "        re = np.array(landmarks[\"right_eye\"])\n",
    "        mo = np.array(landmarks[\"mouth\"])\n",
    "        ch = np.array(landmarks[\"chin\"])\n",
    "        no = np.array(landmarks[\"nose\"])\n",
    "        \n",
    "        # Distancias clave\n",
    "        eye_dist = np.linalg.norm(re - le)\n",
    "        eyes_center = (le + re) / 2\n",
    "        eye_mouth_dist = np.linalg.norm(mo - eyes_center)\n",
    "        nose_chin_dist = np.linalg.norm(ch - no)\n",
    "        face_height = np.linalg.norm(ch - eyes_center)\n",
    "        \n",
    "        if eye_dist == 0 or face_height == 0: return None\n",
    "        \n",
    "        # Ratios invariantes a la escala (distancia / tama√±o cara)\n",
    "        return [\n",
    "            eye_dist / face_height,          # Ancho ojos vs Alto cara\n",
    "            eye_mouth_dist / face_height,    # Ojos-Boca vs Alto cara\n",
    "            nose_chin_dist / face_height,    # Nariz-Barbilla vs Alto cara\n",
    "            eye_dist / eye_mouth_dist        # Relaci√≥n tri√°ngulo facial\n",
    "        ]\n",
    "\n",
    "    def register_person(self, name: str, ratios: List[float]):\n",
    "        \"\"\"Guarda una nueva persona conocida.\"\"\"\n",
    "        pid = len(self.known_profiles) + 1\n",
    "        self.known_profiles[pid] = {\"name\": name, \"ratios\": ratios}\n",
    "        print(f\"‚úÖ Persona registrada: {name}\")\n",
    "\n",
    "    def identify(self, ratios: List[float]) -> str:\n",
    "        \"\"\"Identifica a una persona comparando ratios.\"\"\"\n",
    "        if not ratios: return \"Desconocido\"\n",
    "        \n",
    "        best_match = \"Desconocido\"\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        for pid, profile in self.known_profiles.items():\n",
    "            known_ratios = profile[\"ratios\"]\n",
    "            # Diferencia promedio (Distancia L1)\n",
    "            diff = np.mean([abs(a - b) for a, b in zip(ratios, known_ratios)])\n",
    "            \n",
    "            if diff < self.tolerance and diff < best_score:\n",
    "                best_score = diff\n",
    "                best_match = profile[\"name\"]\n",
    "                \n",
    "        return best_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. L√≥gica de Tracking Inteligente\n",
    "Para evitar que el sistema env√≠e alertas constantes (spam) cuando una persona est√° parada frente a la c√°mara, implementamos una m√°quina de estados simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SecuritySystem:\n",
    "    def __init__(self):\n",
    "        self.detector = LightweightDetector()\n",
    "        self.recognizer = GeometricRecognizer()\n",
    "        \n",
    "        # Estado del tracking\n",
    "        self.person_in_view = False\n",
    "        self.frames_without_person = 0\n",
    "        self.reset_threshold = 10  # Frames para considerar que la persona se fue\n",
    "        self.alerts_log = []\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        detections = self.detector.detect(frame)\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        status_message = \"\"\n",
    "        \n",
    "        if detections:\n",
    "            # Persona detectada\n",
    "            self.frames_without_person = 0\n",
    "            det = detections[0]  # Procesamos la primera cara encontrada\n",
    "            \n",
    "            # Dibujar bounding box\n",
    "            cv2.rectangle(annotated_frame, (det.x, det.y), \n",
    "                         (det.x+det.width, det.y+det.height), (0, 255, 0), 2)\n",
    "            \n",
    "            # Dibujar landmarks\n",
    "            if det.landmarks:\n",
    "                for point in det.landmarks.values():\n",
    "                    cv2.circle(annotated_frame, point, 3, (255, 0, 0), -1)\n",
    "                \n",
    "                # Intentar reconocimiento\n",
    "                ratios = self.recognizer.extract_ratios(det.landmarks)\n",
    "                name = self.recognizer.identify(ratios)\n",
    "                \n",
    "                # Etiqueta\n",
    "                cv2.putText(annotated_frame, name, (det.x, det.y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "                \n",
    "                # L√≥gica de Alerta Inteligente\n",
    "                if not self.person_in_view:\n",
    "                    self.person_in_view = True\n",
    "                    alert = f\"üö® ALERTA: {name} detectado\"\n",
    "                    self.alerts_log.append(alert)\n",
    "                    status_message = alert\n",
    "                    # Auto-registro para demo (si es desconocido y tiene landmarks claros)\n",
    "                    if name == \"Desconocido\" and ratios:\n",
    "                        self.recognizer.register_person(\"Visitante_1\", ratios)\n",
    "                        status_message += \" -> Registrado como Visitante_1\"\n",
    "            \n",
    "        else:\n",
    "            # Nadie en c√°mara\n",
    "            self.frames_without_person += 1\n",
    "            if self.frames_without_person >= self.reset_threshold:\n",
    "                if self.person_in_view:\n",
    "                    self.alerts_log.append(\"‚ÑπÔ∏è Persona sali√≥ de c√°mara\")\n",
    "                self.person_in_view = False\n",
    "        \n",
    "        # Mostrar estado en el frame\n",
    "        if status_message:\n",
    "            cv2.putText(annotated_frame, status_message, (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        elif self.person_in_view:\n",
    "            cv2.putText(annotated_frame, \"Tracking activo...\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "            \n",
    "        return annotated_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ejecuci√≥n con Video\n",
    "Cargamos un video, lo procesamos frame a frame y guardamos el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir el video\")\n",
    "        return\n",
    "    \n",
    "    # Propiedades del video\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Configurar escritor de video\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    system = SecuritySystem()\n",
    "    frame_count = 0\n",
    "    \n",
    "    print(\"Procesando video...\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Procesar frame\n",
    "        processed_frame = system.process_frame(frame)\n",
    "        \n",
    "        # Guardar\n",
    "        out.write(processed_frame)\n",
    "        \n",
    "        # Mostrar progreso cada 30 frames\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\".\", end=\"\")\n",
    "        frame_count += 1\n",
    "        \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"\\n¬°Listo! Video guardado en {output_path}\")\n",
    "    print(\"\\nüìú Log de Alertas:\")\n",
    "    for log in system.alerts_log:\n",
    "        print(log)\n",
    "\n",
    "# --- EJECUCI√ìN ---\n",
    "# Para probar, puedes subir un video llamado 'test_video.mp4' o usar la webcam en local\n",
    "# process_video('test_video.mp4', 'output_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prueba R√°pida (Imagen Est√°tica)\n",
    "Si no tienes un video a mano, probemos el sistema con una imagen generada sint√©ticamente o cargada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una imagen de prueba simple (o cargar una real)\n",
    "# Aqu√≠ simulamos un frame vac√≠o para demostrar que no crashea\n",
    "dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "cv2.putText(dummy_frame, \"Frame de Prueba (Sin Cara)\", (150, 240), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "system = SecuritySystem()\n",
    "result = system.process_frame(dummy_frame)\n",
    "show_frame(result, \"Resultado Prueba\")\n",
    "\n",
    "print(\"Nota: Para ver detecciones reales, sube una imagen con una cara y usa:\")\n",
    "print(\"img = cv2.imread('tu_foto.jpg')\")\n",
    "print(\"res = system.process_frame(img)\")\n",
    "print(\"show_frame(res)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
